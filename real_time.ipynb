{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "from keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "labels = [x for x in 'ABCDEFGHIJKLMNOPQRSTUVWXYZ']\n",
    "labels.append('del')\n",
    "labels.append('nothing')\n",
    "labels.append('space')\n",
    "labels = sorted(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n",
    "pre_trained_model = MobileNetV2(input_shape=(192, 192, 3),\n",
    "                               include_top=False,\n",
    "                               weights='imagenet')\n",
    "for layer in pre_trained_model.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "last_layer = pre_trained_model.get_layer('block_12_depthwise_relu')\n",
    "last_output = last_layer.output\n",
    "\n",
    "x = layers.Flatten()(last_output)\n",
    "x = layers.Dense(1024, activation='relu')(x)\n",
    "x = layers.Dropout(0.2)(x)\n",
    "x = layers.Dense(29, activation='softmax')(x)\n",
    "\n",
    "\n",
    "model = Model(pre_trained_model.input, x)\n",
    "\n",
    "model.load_weights('signlanguage_90_weights.h5')\n",
    "\n",
    "model.compile(optimizer=RMSprop(lr=0.0001),\n",
    "             loss='categorical_crossentropy',\n",
    "             metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera = cv2.VideoCapture(0)\n",
    "\n",
    "top, right, bottom, left = 80, 350, 305, 590\n",
    "\n",
    "while(True):\n",
    "    (grabbed, frame) = camera.read()\n",
    "\n",
    "    frame = cv2.flip(frame, 1)\n",
    "\n",
    "    copy = frame.copy()\n",
    "\n",
    "    (height, width) = frame.shape[:2]\n",
    "\n",
    "    rect = frame[top:bottom, right:left]\n",
    "\n",
    "    img = cv2.resize(rect, (192, 192))\n",
    "    x = image.img_to_array(img) / 255.0\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    images = np.vstack([x])\n",
    "    pred = model.predict(images)\n",
    "    res = labels[np.argmax(pred)]\n",
    "    \n",
    "    cv2.rectangle(copy, (left, top), (right, bottom), (0,255,0), 2)\n",
    "\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    bottomLeftCornerOfText = (10,30)\n",
    "    fontScale = 1\n",
    "    fontColor = (255,255,255)\n",
    "    lineType = 2\n",
    "\n",
    "    cv2.putText(copy, 'Model output: ' + str(res), \n",
    "        bottomLeftCornerOfText, \n",
    "        font, \n",
    "        fontScale,\n",
    "        fontColor,\n",
    "        lineType)\n",
    "    \n",
    "    cv2.imshow(\"Camera\", copy)\n",
    "\n",
    "    # observe the keypress by the user\n",
    "    keypress = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "    # if the user pressed \"q\", then stop looping\n",
    "    if keypress == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "camera.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
